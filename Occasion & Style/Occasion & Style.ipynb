{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from random import randint\n",
    "from numpy import array, argmax, asarray, zeros\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import spacy\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import tensorflow as tf\n",
    "nlp=spacy.load(\"en_core_web_md\")\n",
    "tokenizer = Tokenizer(num_words=5000, oov_token=\"UNKNOWN_TOKEN\")\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Input, Flatten, Dropout\n",
    "from keras.layers import LSTM, Embedding,GRU, Bidirectional\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Masking\n",
    "from keras.layers.recurrent import SimpleRNN, LSTM\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from collections import defaultdict\n",
    "from textwrap import wrap\n",
    "from string import digits\n",
    "pd.options.mode.chained_assignment = None\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer \n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk import punkt\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,recall_score,f1_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from IPython.display import Markdown, display\n",
    "import gensim.utils\n",
    "from xgboost import XGBClassifier\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "rcParams['figure.figsize'] = 12, 8\n",
    "\n",
    "RANDOM_SEED = 24\n",
    "np.random.seed(RANDOM_SEED)\n",
    "#torch.manual_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enter your product query below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn query product into a dataframe (list of strings)\n",
    "brand = ['Fila']\n",
    "product_full_name = ['Trainer sneakers']\n",
    "description = ['leather white trainers with thick shoelaces']\n",
    "brand_category = ['Sneakers, Shoes']\n",
    "details = ['1dsaf']\n",
    "\n",
    "input_df = pd.DataFrame([brand,\n",
    "                         product_full_name,\n",
    "                         description,\n",
    "                         brand_category,\n",
    "                         details]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df.columns = ['brand','product_full_name','description','brand_category','details']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in data\n",
    "full_products_df = pd.read_csv('full_data.csv')\n",
    "tagged_df = pd.read_csv('tagged_product_attributes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge on product data & lower-case description\n",
    "tagged_products_df = tagged_df.merge(full_products_df, left_on='product_id', right_on='product_id')\n",
    "tagged_products_df['description'] = tagged_products_df['description'].str.lower()\n",
    "input_df['description'] = input_df['description'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill empty description with product name\n",
    "def fill_nas(row):\n",
    "  if type(row['description']) == str:\n",
    "    return row['description']\n",
    "  if np.isnan(row['description']):\n",
    "    return row['product_full_name']\n",
    "  return row['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill nas\n",
    "tagged_products_df['description'] = tagged_products_df.apply(fill_nas,axis=1)\n",
    "tagged_products_df.brand_category = tagged_products_df.brand_category.fillna('unknown')\n",
    "\n",
    "input_df['description'] = input_df.apply(fill_nas,axis=1)\n",
    "input_df.brand_category = input_df.brand_category.fillna('unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regex cleaning for brand category\n",
    "tagged_products_df.brand_category = tagged_products_df.brand_category.\\\n",
    "                          apply(lambda x: ','.join(pd.Series\\\n",
    "                          (re.findall(r'[/:]?(\\w+[\\s:]\\w+[\\w+:\\w+]*[\\s]\\w*|\\w+[\\s:]\\w+[\\w+:\\w+]*|\\w+)[/:]?', str(x).lower()))\\\n",
    "                          .drop_duplicates().tolist()))\n",
    "\n",
    "input_df.brand_category = input_df.brand_category.\\\n",
    "                          apply(lambda x: ','.join(pd.Series\\\n",
    "                          (re.findall(r'[/:]?(\\w+[\\s:]\\w+[\\w+:\\w+]*[\\s]\\w*|\\w+[\\s:]\\w+[\\w+:\\w+]*|\\w+)[/:]?', str(x).lower()))\\\n",
    "                          .drop_duplicates().tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a set of all the categories\n",
    "def add_cat(x):\n",
    "  cats = re.findall(r'[,]?(\\w+[\\s]\\w+[\\s]\\w+|\\w+[\\s]?\\w+|\\w+)[,]?',x)\n",
    "  for cat in cats:\n",
    "    category.add(cat)\n",
    "  return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove duplicates\n",
    "def remove_dupe(alist):\n",
    "  blist = []\n",
    "  for cat in alist:\n",
    "    blist.append(cat.strip())\n",
    "  return ','.join(pd.Series(blist).drop_duplicates().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove duplicates in a single line of brand category\n",
    "remove_digits = str.maketrans('', '', digits)\n",
    "tagged_products_df.brand_category = tagged_products_df.brand_category\\\n",
    "                  .apply(lambda x: x.replace(':', ','))\\\n",
    "                  .apply(lambda x: x.translate(remove_digits))\\\n",
    "                  .apply(lambda x: remove_dupe(x.split(',')))\n",
    "category = set()\n",
    "tagged_products_df.brand_category.apply(add_cat)\n",
    "\n",
    "input_df.brand_category = input_df.brand_category\\\n",
    "                  .apply(lambda x: x.replace(':', ','))\\\n",
    "                  .apply(lambda x: x.translate(remove_digits))\\\n",
    "                  .apply(lambda x: remove_dupe(x.split(',')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge duplicate categories into ones\n",
    "to_replace = [[r'(\\bt,shirts\\b)','tees'],\n",
    "[r'(\\baccessories\\b|\\baccessory\\b|\\ball_accessories\\b)','accessories'],\n",
    "[r'(\\bbelt bags\\b|\\bbeltbags\\b)','beltbags'],\n",
    "[r'(\\bcoatsjacketswa\\b)','coats_and_jackets'],\n",
    "[r'(\\bcross body\\b|\\bcrossbody\\b)','crossbody'],\n",
    "[r'(\\bflat shoes\\b|\\bflat\\b)','flats'],\n",
    "[r'(\\bhandbagsshoes\\b)','handbags,shoes'],\n",
    "[r'(\\bjacketsvests\\b)','jackets,vests'],\n",
    "[r'(\\bjackets\\b|\\bjacket\\b)','jackets'],\n",
    "[r'(\\bdressesandjumpsuits\\b)','dresses,jumpsuits'],\n",
    "[r'(\\bbolerosjacketsvests\\b)','boleros,jackets,vests'],\n",
    "[r'(\\bapparelaccessories\\b)','apparel,accessories'],\n",
    "[r'(\\blow top\\b|\\blowtop\\b)','lowtop'],\n",
    "[r'(\\bmini bags\\b)','minibags'],\n",
    "[r'(\\bpantsshortsjumpsuits\\b)','pants,shorts,jumpsuits'],\n",
    "[r'(\\bshirts_tops\\b)','shirts,tops'],\n",
    "[r'(\\bshorts\\b)','short'],\n",
    "[r'(\\bshoulder bags\\b|\\bshoulder_bags\\b)','shoulderbags'],\n",
    "[r'(\\bsweatshirts_sweatpants\\b)','sweatshirts,sweatpants'],\n",
    "[r'(\\btshirts_tanktops\\b)','tees,tanktops'],\n",
    "[r'(\\btshirtstanks\\b)','tees,tanktops'],\n",
    "[r'(\\bwomensapparel\\b)','women'],\n",
    "[r'(\\bclutch bags\\b)','clutches'],\n",
    "[r'(\\bjumpsuit\\b)','jumpsuits'],\n",
    "[r'(\\bmidi dresses\\b)','midi'],\n",
    "[r'(\\bromper\\b)','rompers'],\n",
    "[r'(\\bskirt\\b)','skirts'],\n",
    "[r'(\\bsweater\\b)','sweaters'],\n",
    "[r'(\\btote bags\\b)','totes'],\n",
    "[r'(\\btop\\b)','tops']]\n",
    "\n",
    "for replace in to_replace:\n",
    "    tagged_products_df.brand_category = tagged_products_df.brand_category.apply(lambda x: re.sub(replace[0],replace[1], x.lower()))\n",
    "for replace in to_replace:\n",
    "    input_df.brand_category = input_df.brand_category.apply(lambda x: re.sub(replace[0],replace[1], x.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#strip puncs for brands\n",
    "import string\n",
    "tagged_products_df.brand = tagged_products_df.brand.apply(str.lower).apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n",
    "\n",
    "input_df.brand = input_df.brand.apply(str.lower).apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge duplicate brands into ones\n",
    "brand_replace = [[r'®',''],\n",
    "[r'(\\bvictoria victoria beckham\\b)','victoria beckham']]\n",
    "\n",
    "for replace in brand_replace:\n",
    "    tagged_products_df.brand = tagged_products_df.brand.apply(lambda x: re.sub(replace[0],replace[1], x))\n",
    "    \n",
    "for replace in brand_replace:\n",
    "    input_df.brand = input_df.brand.apply(lambda x: re.sub(replace[0],replace[1], x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop duplicates\n",
    "tagged_products_df = tagged_products_df[['attribute_name','attribute_value','brand','product_full_name','description','brand_category']].drop_duplicates()\n",
    "\n",
    "input_df = input_df[['brand','product_full_name','description','brand_category', 'details']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean specific DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make specific datatframes\n",
    "style_df = tagged_products_df[tagged_products_df['attribute_name']=='style']\n",
    "attributes_df = tagged_products_df[tagged_products_df['attribute_name']=='occasion']\n",
    "input_style_df =input_df.drop('details', axis=1)\n",
    "input_occasion_df =input_df.drop('details', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes_df = attributes_df[['attribute_value', 'brand','product_full_name','description','brand_category']]\n",
    "style_df = style_df[['attribute_value', 'brand','product_full_name','description','brand_category']]\n",
    "input_style_df =input_style_df[['brand','product_full_name','description','brand_category']]\n",
    "input_occasion_df =input_occasion_df[['brand','product_full_name','description','brand_category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make attribute values lowercase\n",
    "attributes_df.attribute_value = attributes_df.attribute_value.str.lower()\n",
    "style_df.attribute_value = style_df.attribute_value.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge similar attributes into ones\n",
    "attributes_df.attribute_value = attributes_df.attribute_value.str.replace('day to night','daytonight').str.replace('night out','nightout')\n",
    "style_df.attribute_value = style_df.attribute_value.str.replace('businesscasual','business casual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 hot encoding for responses\n",
    "for style in style_df.attribute_value.unique():\n",
    "    style_df[f'{style}_target'] = style_df['attribute_value'] == style\n",
    "for attribute in attributes_df.attribute_value.unique():\n",
    "    attributes_df[f'{attribute}_target'] = attributes_df['attribute_value'] == attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_df = style_df.drop_duplicates()\n",
    "attributes_df = attributes_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#processing same items with multiple rows\n",
    "styleindex = style_df.set_index(['brand','product_full_name','description','brand_category']).index\n",
    "\n",
    "for ind in styleindex:\n",
    "  brand, name, description, brand_category = ind\n",
    "  values = style_df.set_index(['brand','product_full_name','description','brand_category']).loc[ind]['attribute_value']\n",
    "  for value in values:\n",
    "    m = (style_df['brand']==brand)\\\n",
    "        &(style_df['product_full_name']==name)\\\n",
    "        &(style_df['description']==description)\\\n",
    "        &(style_df['brand_category']==brand_category)\n",
    "    style_df.loc[m, f'{value}_target'] = True\n",
    "\n",
    "style_df = style_df.drop('attribute_value',axis=1).drop_duplicates()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributeindex = attributes_df.set_index(['brand','product_full_name','description','brand_category']).index\n",
    "for ind in attributeindex:\n",
    "  brand, name, description, brand_category = ind\n",
    "  values = attributes_df.set_index(['brand','product_full_name','description','brand_category']).loc[ind]['attribute_value']\n",
    "  for value in values:\n",
    "    m = (attributes_df['brand']==brand)\\\n",
    "        &(attributes_df['product_full_name']==name)\\\n",
    "        &(attributes_df['description']==description)\\\n",
    "        &(attributes_df['brand_category']==brand_category)\n",
    "    attributes_df.loc[m, f'{value}_target'] = True\n",
    "    \n",
    "attributes_df = attributes_df.drop('attribute_value',axis=1).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = [col.replace('_target','') for col in attributes_df.columns if 'target' in col]\n",
    "styles = [col.replace('_target','') for col in style_df.columns if 'target' in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for attribute in attributes:\n",
    "  attributes_df[f'{attribute}_target'] = attributes_df[f'{attribute}_target'].astype(float)\n",
    "for style in styles:\n",
    "  style_df[f'{style}_target'] = style_df[f'{style}_target'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_category(categories, cat):\n",
    "  for c in categories.split(','):\n",
    "    if c == cat:\n",
    "      return 1\n",
    "  return 0\n",
    "\n",
    "for cat in category:\n",
    "  attributes_df[cat] = attributes_df['brand_category'].apply(lambda x: one_hot_category(x, cat))\n",
    "\n",
    "for cat in category:\n",
    "  style_df[cat] = style_df['brand_category'].apply(lambda x: one_hot_category(x, cat))\n",
    "\n",
    "for cat in category:\n",
    "  input_style_df[cat] = input_style_df['brand_category'].apply(lambda x: one_hot_category(x, cat))\n",
    "\n",
    "for cat in category:\n",
    "  input_occasion_df[cat] = input_occasion_df['brand_category'].apply(lambda x: one_hot_category(x, cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encoding for brands\n",
    "attribute_brand_le = LabelEncoder()\n",
    "attributes_df['brand_le'] = attribute_brand_le.fit_transform(attributes_df['brand'].values)\n",
    "\n",
    "style_brand_le = LabelEncoder()\n",
    "style_df['brand_le'] = style_brand_le.fit_transform(style_df['brand'].values)\n",
    "\n",
    "style_mapping = style_df.set_index(['brand','brand_le']).index.unique()\n",
    "style_mapping = {brand[0]:brand[1] for brand in style_mapping}\n",
    "\n",
    "occasion_mapping = attributes_df.set_index(['brand','brand_le']).index.unique()\n",
    "occasion_mapping = {brand[0]:brand[1] for brand in occasion_mapping}\n",
    "\n",
    "\n",
    "input_style_df['brand_le'] = input_style_df['brand'].map(style_mapping)\n",
    "input_occasion_df['brand_le'] = input_occasion_df['brand'].map(occasion_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#strip puncs for product full names\n",
    "attributes_df.product_full_name = attributes_df.product_full_name.apply(str.lower).apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n",
    "style_df.product_full_name = style_df.product_full_name.apply(str.lower).apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n",
    "input_style_df.product_full_name = input_style_df.product_full_name.apply(str.lower).apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n",
    "input_occasion_df.product_full_name = input_occasion_df.product_full_name.apply(str.lower).apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check for duplicates\n",
    "attributes_df.drop_duplicates(inplace=True)\n",
    "style_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatizer function\n",
    "lem = WordNetLemmatizer()\n",
    "def lem_sentences(sentence):\n",
    "    tokens = gensim.utils.tokenize(sentence)\n",
    "    lemmed_tokens = [lem.lemmatize(token) for token in tokens]\n",
    "    return ' '.join(lemmed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#strip puncs for descrps\n",
    "import string\n",
    "attributes_df.description = attributes_df.description.apply(str.lower).apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n",
    "style_df.description = style_df.description.apply(str.lower).apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n",
    "\n",
    "attributes_df.product_full_name = attributes_df.product_full_name.apply(str.lower).apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n",
    "style_df.product_full_name = style_df.product_full_name.apply(str.lower).apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n",
    "\n",
    "input_occasion_df.description = input_occasion_df.description.apply(str.lower).apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n",
    "input_style_df.product_full_name = input_style_df.product_full_name.apply(str.lower).apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemmatize descriptions\n",
    "attributes_df.description = attributes_df.description.apply(lem_sentences)\n",
    "style_df.description = style_df.description.apply(lem_sentences)\n",
    "\n",
    "attributes_df.product_full_name = attributes_df.product_full_name.apply(lem_sentences)\n",
    "style_df.product_full_name = style_df.product_full_name.apply(lem_sentences)\n",
    "\n",
    "input_occasion_df.description = input_occasion_df.description.apply(lem_sentences)\n",
    "input_style_df.description = input_style_df.description.apply(lem_sentences)\n",
    "\n",
    "input_occasion_df.product_full_name = input_occasion_df.product_full_name.apply(lem_sentences)\n",
    "input_style_df.product_full_name = input_style_df.product_full_name.apply(lem_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove stopwords\n",
    "attributes_df.description = attributes_df.description.apply(remove_stopwords)\n",
    "style_df.description = style_df.description.apply(remove_stopwords)\n",
    "\n",
    "attributes_df.product_full_name = attributes_df.product_full_name.apply(remove_stopwords)\n",
    "style_df.product_full_name = style_df.product_full_name.apply(remove_stopwords)\n",
    "\n",
    "input_occasion_df.description = input_occasion_df.description.apply(remove_stopwords)\n",
    "input_style_df.description = input_style_df.description.apply(remove_stopwords)\n",
    "\n",
    "input_occasion_df.product_full_name = input_occasion_df.product_full_name.apply(remove_stopwords)\n",
    "input_style_df.product_full_name = input_style_df.product_full_name.apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_occasion_df.fillna(0,inplace=True)\n",
    "input_style_df.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "#make tfidf function cr to Prof Yu Chen\n",
    "def tfidf(series):\n",
    "    vectorizer = TfidfVectorizer(min_df=2,\n",
    "                                 max_df=0.3)\n",
    "    X = vectorizer.fit_transform(series)\n",
    "\n",
    "    tf_idf_lookup_table = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
    "\n",
    "\n",
    "    DOCUMENT_SUM_COLUMN = \"DOCUMENT_TF_IDF_SUM\"\n",
    "\n",
    "    tf_idf_lookup_table[DOCUMENT_SUM_COLUMN] = tf_idf_lookup_table.sum(axis=1)\n",
    "    available_tf_idf_scores = tf_idf_lookup_table.columns \n",
    "    available_tf_idf_scores = list(map( lambda x: x.lower(), available_tf_idf_scores)) \n",
    "    return tf_idf_lookup_table, available_tf_idf_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make embed function cr to Prof Yu Chen\n",
    "def embed(textdf, available_tf_idf_scores, tf_idf_lookup_table):\n",
    "    text_vectors = []\n",
    "\n",
    "    for idx, text in enumerate(textdf): \n",
    "        tokens = nlp(text)\n",
    "\n",
    "        total_tf_idf_score_per_document = 0\n",
    "\n",
    "\n",
    "        running_total_word_embedding = np.zeros(300) \n",
    "        for token in tokens:\n",
    "\n",
    "       \n",
    "            if token.has_vector and token.text.lower() in available_tf_idf_scores:\n",
    "\n",
    "                tf_idf_score = tf_idf_lookup_table.loc[idx, token.text.lower()]\n",
    "            \n",
    "                running_total_word_embedding += tf_idf_score * token.vector\n",
    "\n",
    "                total_tf_idf_score_per_document += tf_idf_score\n",
    "\n",
    "        document_embedding = running_total_word_embedding / (total_tf_idf_score_per_document + 1e-6)\n",
    "        text_vectors.append(document_embedding)\n",
    "    return text_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf for attribute \n",
    "d_tf_idf_lookup_table, d_available_tf_idf_scores = tfidf(attributes_df.description)\n",
    "d_text_vector = embed(attributes_df.description, d_available_tf_idf_scores, d_tf_idf_lookup_table)\n",
    "p_tf_idf_lookup_table, p_available_tf_idf_scores = tfidf(attributes_df.product_full_name)\n",
    "p_text_vector = embed(attributes_df.product_full_name, p_available_tf_idf_scores, p_tf_idf_lookup_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf for style \n",
    "d_style_lu_tb, d_style_scores = tfidf(style_df.description)\n",
    "d_style_vector = embed(style_df.description, d_style_scores, d_style_lu_tb)\n",
    "p_style_lu_tb, p_style_scores = tfidf(style_df.product_full_name)\n",
    "p_style_vector = embed(style_df.product_full_name, p_style_scores, p_style_lu_tb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combined vec for attribute\n",
    "combined_vectors = []\n",
    "for idx in range(len(p_text_vector)):\n",
    "    combined_vector = 0.2*p_text_vector[idx] + 0.8*d_text_vector[idx]\n",
    "    combined_vectors.append(combined_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combined vec for style\n",
    "style_combined_vectors = []\n",
    "for idx in range(len(p_style_vector)):\n",
    "    style_combined_vector = 0.4*p_style_vector[idx] + 0.6*d_style_vector[idx]\n",
    "    style_combined_vectors.append(style_combined_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf for input occasion\n",
    "d_tf_idf_lookup_table_input, d_available_tf_idf_scores_input = tfidf(input_occasion_df.description)\n",
    "d_input_occasion_vector = embed(input_occasion_df.description, d_available_tf_idf_scores_input, d_tf_idf_lookup_table_input)\n",
    "p_tf_idf_lookup_table_input, p_available_tf_idf_scores_input = tfidf(input_occasion_df.product_full_name)\n",
    "p_input_occasion_vector = embed(input_occasion_df.product_full_name, p_available_tf_idf_scores_input, p_tf_idf_lookup_table_input)\n",
    "\n",
    "input_occasion_combined_vectors = []\n",
    "for idx in range(len(p_input_occasion_vector)):\n",
    "    input_occasion_combined_vector = 0.2*p_input_occasion_vector[idx] + 0.8*d_input_occasion_vector[idx]\n",
    "    input_occasion_combined_vectors.append(input_occasion_combined_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf for input style\n",
    "d_tf_idf_lookup_table_input_style, d_available_tf_idf_scores_input_style = tfidf(input_style_df.description)\n",
    "d_input_style_vector = embed(input_style_df.description, d_available_tf_idf_scores_input_style, d_tf_idf_lookup_table_input_style)\n",
    "p_tf_idf_lookup_table_input_style, p_available_tf_idf_scores_input_style = tfidf(input_style_df.product_full_name)\n",
    "p_input_style_vector = embed(input_style_df.product_full_name, p_available_tf_idf_scores_input_style, p_tf_idf_lookup_table_input_style)\n",
    "\n",
    "input_style_combined_vectors = []\n",
    "for idx in range(len(p_input_style_vector)):\n",
    "    input_style_combined_vector = 0.2*p_input_style_vector[idx] + 0.8*d_input_style_vector[idx]\n",
    "    input_style_combined_vectors.append(input_style_combined_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reset index so that we can join word embeds later\n",
    "attributes_df = attributes_df.iloc[:,1:].reset_index().drop('index',axis=1)\n",
    "style_df = style_df.reset_index().drop('index',axis=1)\n",
    "input_occasion_df = input_occasion_df.reset_index().drop('index',axis=1)\n",
    "input_style_df = input_style_df.reset_index().drop('index',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup models\n",
    "log_model = LogisticRegression()\n",
    "svc_model = LinearSVC()\n",
    "rf_model = RandomForestClassifier(n_estimators=500,min_samples_split=5,min_samples_leaf=3)\n",
    "knn_model = KNeighborsClassifier(n_neighbors=3)\n",
    "gb_model = XGBClassifier(n_estimators=150, max_depth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining models and targets\n",
    "models = [log_model, svc_model, rf_model, knn_model, gb_model]\n",
    "occassions = pd.Series([col if '_target' in col else np.nan for col in attributes_df.columns]).dropna().tolist()\n",
    "styles = pd.Series([col if '_target' in col else np.nan for col in style_df.columns]).dropna().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make predict function\n",
    "def predict(models, responses, DF, vector, upsample=False, multiclass=False, testsize=0.1):\n",
    "    from sklearn.metrics import accuracy_score,recall_score,f1_score\n",
    "    from imblearn.over_sampling import RandomOverSampler\n",
    "    best_model_dict, prediction_tags = {}, {}\n",
    "    for response in responses:\n",
    "        best_score = 0\n",
    "        best_model,best_predictions = None, None\n",
    "        for model in models:\n",
    "            df = DF.copy()\n",
    "            df = df.loc[:,responses[0]:]\n",
    "            for i in df.columns:\n",
    "                if 'target' not in i:\n",
    "                    slicing_index = i\n",
    "                    break\n",
    "            X = pd.concat([df.loc[:,slicing_index:],pd.DataFrame(vector).reindex(df.loc[:,slicing_index:].index)], axis=1)\n",
    "            y = df[response]\n",
    "            dataframe = pd.concat([X,y], axis=1).fillna(0)\n",
    "            y = dataframe[response]\n",
    "            X = dataframe.iloc[:,:-1]\n",
    "            X_train, X_test,y_train, y_test = train_test_split(X.values,y.values, random_state=66, test_size=testsize, shuffle=True,stratify=y)\n",
    "            if upsample:\n",
    "                ros = RandomOverSampler(random_state=24)\n",
    "                X_train, y_train = ros.fit_resample(X_train, y_train)\n",
    "            if multiclass:\n",
    "                model = OneVsRestClassifier(model)\n",
    "            model.fit(X_train, y_train)\n",
    "            prediction = model.predict(X_test)\n",
    "            accuracy = accuracy_score(y_test, prediction)\n",
    "            if not multiclass:\n",
    "                recall = recall_score(y_test, prediction)\n",
    "                score = f1_score(y_test, prediction)\n",
    "            else:\n",
    "                score = accuracy\n",
    "            if score >= best_score:\n",
    "                best_score = score\n",
    "                best_model = model\n",
    "                best_predictions = prediction\n",
    "        print(f'The best combined score for {response} is {best_score} with {type(best_model).__name__}')\n",
    "        best_model_dict[response] = best_model\n",
    "        prediction_tags[response] = best_predictions\n",
    "    return best_model_dict, prediction_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best combined score for work_target is 0.628158844765343 with KNeighborsClassifier\n",
      "The best combined score for weekend_target is 0.8609271523178809 with LinearSVC\n",
      "The best combined score for vacation_target is 0.5357142857142858 with LogisticRegression\n",
      "The best combined score for daytonight_target is 0.8519736842105263 with RandomForestClassifier\n",
      "The best combined score for nightout_target is 0.5321100917431193 with KNeighborsClassifier\n",
      "The best combined score for workout_target is 0.5454545454545454 with KNeighborsClassifier\n",
      "The best combined score for coldweather_target is 0.4918032786885246 with KNeighborsClassifier\n"
     ]
    }
   ],
   "source": [
    "#training models for occasions\n",
    "best_occassion_models, best_occassion_predictions = predict(models, occassions, attributes_df, combined_vectors, upsample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best combined score for classic_target is 0.5901639344262295 with KNeighborsClassifier\n",
      "The best combined score for business casual_target is 0.6343612334801763 with XGBClassifier\n",
      "The best combined score for androgynous_target is 0.5581395348837209 with XGBClassifier\n",
      "The best combined score for casual_target is 0.8429423459244533 with RandomForestClassifier\n",
      "The best combined score for modern_target is 0.7075208913649025 with RandomForestClassifier\n",
      "The best combined score for edgy_target is 0.49746192893401014 with XGBClassifier\n",
      "The best combined score for romantic_target is 0.5074626865671641 with KNeighborsClassifier\n",
      "The best combined score for athleisure_target is 0.7272727272727274 with KNeighborsClassifier\n",
      "The best combined score for boho_target is 0.4512195121951219 with LogisticRegression\n",
      "The best combined score for glam_target is 0.4895104895104895 with LogisticRegression\n",
      "The best combined score for retro_target is 0.23076923076923075 with RandomForestClassifier\n"
     ]
    }
   ],
   "source": [
    "#training models for styles\n",
    "best_style_models, best_style_predictions = predict(models, styles, style_df, style_combined_vectors, upsample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integer_encode_documents(docs,tokenizer):\n",
    "    return tokenizer.texts_to_sequences(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_lstm_df(tag):\n",
    "        tag_data = pd.read_csv('tagged_product_attributes.csv')\n",
    "        full_data = pd.read_csv('full_data.csv')\n",
    "        tag_data['attribute_value']=tag_data['attribute_value'].str.lower()\n",
    "        tags_df=tag_data[tag_data['attribute_name'].str.lower()==tag]\n",
    "        tags_1=tags_df.drop_duplicates(subset=['product_id','attribute_value'])\n",
    "        if tag == 'style':\n",
    "            tags_1.attribute_value = tags_1.attribute_value.str.replace('businesscasual','business casual')\n",
    "        if tag == 'occasion':\n",
    "            tags_1.attribute_value = tags_1.attribute_value.str.replace('day to night','daytonight').str.replace('night out','nightout')\n",
    "        tags_2=pd.concat([tags_1,pd.get_dummies(tags_1['attribute_value'])],axis=1)\n",
    "        tags=list(tags_2['attribute_value'].unique())\n",
    "        full=full_data[['product_id','brand','brand_category','product_full_name','description','details']]\\\n",
    "        .drop_duplicates(subset=['product_id'])\n",
    "        full=full.fillna('')\n",
    "        full['input']=full[['brand','brand_category','product_full_name','description','details']].agg(' '.join, axis=1).str.lower()\n",
    "        full['input'] = full['input'].replace(r\"[^a-z0-9\\s]+\", \"\")\n",
    "        out_tag=tags_2.merge(full,how='left',on='product_id')\n",
    "        out_tag=out_tag.groupby(['product_id','input'])[tags].sum().reset_index()\n",
    "        out_tag['input']=out_tag['input'].apply(lambda x: lem_sentences(x))\n",
    "        if tag == 'style':\n",
    "            out_tag['business casual'] = out_tag['business casual'].replace(2,1)\n",
    "        if tag == 'occasion':\n",
    "            out_tag['daytonight'] = out_tag['daytonight'].replace(2,1)\n",
    "            out_tag['nightout'] = out_tag['nightout'].replace(2,1)\n",
    "        return out_tag, tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "styles_df, styles = prep_lstm_df('style')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "occasion_df, occasions = prep_lstm_df('occasion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "def load_glove_vectors():\n",
    "    embeddings_index = {}\n",
    "    with open('glove.6B.100d.txt', encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = asarray(values[1:], dtype='float64')\n",
    "            embeddings_index[word] = coefs\n",
    "    print('Loaded %s word vectors.' % len(embeddings_index))\n",
    "    return embeddings_index\n",
    "\n",
    "\n",
    "embeddings_index = load_glove_vectors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "def f1_metric(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val\n",
    "def make_binary_classification_rnn_model(embedding_matrix, VOCAB_SIZE):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(VOCAB_SIZE, 100, weights=[embedding_matrix],trainable=False))\n",
    "    model.add(Masking(mask_value=0.0)) \n",
    "    model.add(Bidirectional(LSTM(units=64)))\n",
    "    model.add(Dense(16))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    model.compile(optimizer='adam', \n",
    "                  loss='categorical_crossentropy', \n",
    "                  metrics=['accuracy',f1_metric])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_model(i, df):\n",
    "    inputdata=df['input'].tolist()\n",
    "    label=df[\"{}\".format(i)].tolist()\n",
    "    stopwords_removed_docs = list(\n",
    "        map(lambda doc: \" \".join([token.text for token in nlp(doc) if not token.is_stop]), inputdata))\n",
    "    tokenizer.fit_on_texts(stopwords_removed_docs)\n",
    "    encoded_docs = integer_encode_documents(stopwords_removed_docs, tokenizer)\n",
    "    padded_docs = pad_sequences(encoded_docs, padding='post')\n",
    "    labels = to_categorical(encoder.fit_transform(label))\n",
    "    VOCAB_SIZE = int(len(tokenizer.word_index) * 1.1)\n",
    "    embedding_matrix = zeros((VOCAB_SIZE, 100))\n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None: \n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    model = make_binary_classification_rnn_model(embedding_matrix, VOCAB_SIZE)\n",
    "    model.fit(padded_docs, labels, validation_split = 0.1, epochs=5, verbose=1)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting for androgynous:\n",
      "Train on 3524 samples, validate on 392 samples\n",
      "Epoch 1/5\n",
      "3524/3524 [==============================] - 28s 8ms/step - loss: 0.4333 - accuracy: 0.8121 - f1_metric: 0.8117 - val_loss: 0.2409 - val_accuracy: 0.9362 - val_f1_metric: 0.9255\n",
      "Epoch 2/5\n",
      "3524/3524 [==============================] - 27s 8ms/step - loss: 0.3691 - accuracy: 0.8351 - f1_metric: 0.8345 - val_loss: 0.2254 - val_accuracy: 0.9362 - val_f1_metric: 0.9255\n",
      "Epoch 3/5\n",
      "3524/3524 [==============================] - 27s 8ms/step - loss: 0.3377 - accuracy: 0.8482 - f1_metric: 0.8474 - val_loss: 0.2022 - val_accuracy: 0.9362 - val_f1_metric: 0.9255\n",
      "Epoch 4/5\n",
      "3524/3524 [==============================] - 26s 7ms/step - loss: 0.3148 - accuracy: 0.8553 - f1_metric: 0.8564 - val_loss: 0.2056 - val_accuracy: 0.9388 - val_f1_metric: 0.9279\n",
      "Epoch 5/5\n",
      "3524/3524 [==============================] - 27s 8ms/step - loss: 0.2905 - accuracy: 0.8703 - f1_metric: 0.8694 - val_loss: 0.2245 - val_accuracy: 0.9235 - val_f1_metric: 0.9135\n",
      "Predicting for athleisure:\n",
      "Train on 3524 samples, validate on 392 samples\n",
      "Epoch 1/5\n",
      "3524/3524 [==============================] - 27s 8ms/step - loss: 0.1709 - accuracy: 0.9461 - f1_metric: 0.9445 - val_loss: 0.1204 - val_accuracy: 0.9770 - val_f1_metric: 0.9784\n",
      "Epoch 2/5\n",
      "3524/3524 [==============================] - 27s 8ms/step - loss: 0.0949 - accuracy: 0.9736 - f1_metric: 0.9738 - val_loss: 0.1107 - val_accuracy: 0.9694 - val_f1_metric: 0.9712\n",
      "Epoch 3/5\n",
      "3524/3524 [==============================] - 27s 8ms/step - loss: 0.0759 - accuracy: 0.9742 - f1_metric: 0.9744 - val_loss: 0.1037 - val_accuracy: 0.9694 - val_f1_metric: 0.9712\n",
      "Epoch 4/5\n",
      "3524/3524 [==============================] - 27s 8ms/step - loss: 0.0575 - accuracy: 0.9793 - f1_metric: 0.9794 - val_loss: 0.0929 - val_accuracy: 0.9770 - val_f1_metric: 0.9784\n",
      "Epoch 5/5\n",
      "3524/3524 [==============================] - 27s 8ms/step - loss: 0.0494 - accuracy: 0.9824 - f1_metric: 0.9825 - val_loss: 0.0933 - val_accuracy: 0.9770 - val_f1_metric: 0.9784\n",
      "Predicting for boho:\n",
      "Train on 3524 samples, validate on 392 samples\n",
      "Epoch 1/5\n",
      "3524/3524 [==============================] - 27s 8ms/step - loss: 0.3215 - accuracy: 0.8862 - f1_metric: 0.8871 - val_loss: 0.4340 - val_accuracy: 0.8214 - val_f1_metric: 0.8173\n",
      "Epoch 2/5\n",
      "3524/3524 [==============================] - 26s 7ms/step - loss: 0.2602 - accuracy: 0.9010 - f1_metric: 0.9017 - val_loss: 0.4830 - val_accuracy: 0.8189 - val_f1_metric: 0.8077\n",
      "Epoch 3/5\n",
      "3524/3524 [==============================] - 26s 7ms/step - loss: 0.2401 - accuracy: 0.9041 - f1_metric: 0.9048 - val_loss: 0.4722 - val_accuracy: 0.8163 - val_f1_metric: 0.8125\n",
      "Epoch 4/5\n",
      "3524/3524 [==============================] - 26s 7ms/step - loss: 0.2100 - accuracy: 0.9166 - f1_metric: 0.9172 - val_loss: 0.4631 - val_accuracy: 0.8240 - val_f1_metric: 0.8197\n",
      "Epoch 5/5\n",
      "3524/3524 [==============================] - 26s 7ms/step - loss: 0.1929 - accuracy: 0.9257 - f1_metric: 0.9262 - val_loss: 0.4620 - val_accuracy: 0.8316 - val_f1_metric: 0.8269\n",
      "Predicting for business casual:\n",
      "Train on 3524 samples, validate on 392 samples\n",
      "Epoch 1/5\n",
      "3524/3524 [==============================] - 27s 8ms/step - loss: 0.5242 - accuracy: 0.7389 - f1_metric: 0.7390 - val_loss: 0.3465 - val_accuracy: 0.8724 - val_f1_metric: 0.8798\n",
      "Epoch 2/5\n",
      "3524/3524 [==============================] - 27s 8ms/step - loss: 0.4377 - accuracy: 0.8011 - f1_metric: 0.8007 - val_loss: 0.3578 - val_accuracy: 0.8469 - val_f1_metric: 0.8558\n",
      "Epoch 3/5\n",
      "3524/3524 [==============================] - 27s 8ms/step - loss: 0.3988 - accuracy: 0.8144 - f1_metric: 0.8159 - val_loss: 0.3828 - val_accuracy: 0.8393 - val_f1_metric: 0.8486\n",
      "Epoch 4/5\n",
      "3524/3524 [==============================] - 27s 8ms/step - loss: 0.3573 - accuracy: 0.8388 - f1_metric: 0.8381 - val_loss: 0.5028 - val_accuracy: 0.8087 - val_f1_metric: 0.8125\n",
      "Epoch 5/5\n",
      "3524/3524 [==============================] - 26s 8ms/step - loss: 0.3294 - accuracy: 0.8513 - f1_metric: 0.8505 - val_loss: 0.5137 - val_accuracy: 0.8087 - val_f1_metric: 0.8125\n",
      "Predicting for casual:\n",
      "Train on 3524 samples, validate on 392 samples\n",
      "Epoch 1/5\n",
      "3524/3524 [==============================] - 27s 8ms/step - loss: 0.5368 - accuracy: 0.7157 - f1_metric: 0.7179 - val_loss: 0.3823 - val_accuracy: 0.8367 - val_f1_metric: 0.8389\n",
      "Epoch 2/5\n",
      "3524/3524 [==============================] - 26s 7ms/step - loss: 0.4422 - accuracy: 0.7818 - f1_metric: 0.7835 - val_loss: 0.4081 - val_accuracy: 0.8087 - val_f1_metric: 0.8053\n",
      "Epoch 3/5\n",
      "3524/3524 [==============================] - 26s 7ms/step - loss: 0.3976 - accuracy: 0.8138 - f1_metric: 0.8133 - val_loss: 0.4213 - val_accuracy: 0.8010 - val_f1_metric: 0.7909\n",
      "Epoch 4/5\n",
      "3524/3524 [==============================] - 26s 8ms/step - loss: 0.3717 - accuracy: 0.8263 - f1_metric: 0.8277 - val_loss: 0.3556 - val_accuracy: 0.8265 - val_f1_metric: 0.8221\n",
      "Epoch 5/5\n",
      "3524/3524 [==============================] - 26s 7ms/step - loss: 0.3384 - accuracy: 0.8439 - f1_metric: 0.8452 - val_loss: 0.3443 - val_accuracy: 0.8316 - val_f1_metric: 0.8269\n",
      "Predicting for classic:\n",
      "Train on 3524 samples, validate on 392 samples\n",
      "Epoch 1/5\n",
      "3524/3524 [==============================] - 27s 8ms/step - loss: 0.6006 - accuracy: 0.6740 - f1_metric: 0.6726 - val_loss: 0.7897 - val_accuracy: 0.4643 - val_f1_metric: 0.4736\n",
      "Epoch 2/5\n",
      "3524/3524 [==============================] - 27s 8ms/step - loss: 0.5287 - accuracy: 0.7446 - f1_metric: 0.7407 - val_loss: 0.6667 - val_accuracy: 0.6173 - val_f1_metric: 0.6250\n",
      "Epoch 3/5\n",
      "3524/3524 [==============================] - 26s 7ms/step - loss: 0.4939 - accuracy: 0.7531 - f1_metric: 0.7531 - val_loss: 0.6814 - val_accuracy: 0.6122 - val_f1_metric: 0.6202\n",
      "Epoch 4/5\n",
      "3524/3524 [==============================] - 26s 7ms/step - loss: 0.4678 - accuracy: 0.7778 - f1_metric: 0.7776 - val_loss: 0.6799 - val_accuracy: 0.6020 - val_f1_metric: 0.6106\n",
      "Epoch 5/5\n",
      "3524/3524 [==============================] - 27s 8ms/step - loss: 0.4397 - accuracy: 0.7917 - f1_metric: 0.7914 - val_loss: 0.6339 - val_accuracy: 0.6429 - val_f1_metric: 0.6418\n",
      "Predicting for edgy:\n",
      "Train on 3524 samples, validate on 392 samples\n",
      "Epoch 1/5\n",
      "3524/3524 [==============================] - 27s 8ms/step - loss: 0.4514 - accuracy: 0.8002 - f1_metric: 0.8018 - val_loss: 0.4561 - val_accuracy: 0.7959 - val_f1_metric: 0.8077\n",
      "Epoch 2/5\n",
      "3524/3524 [==============================] - 27s 8ms/step - loss: 0.3871 - accuracy: 0.8283 - f1_metric: 0.8297 - val_loss: 0.4456 - val_accuracy: 0.8036 - val_f1_metric: 0.8149\n",
      "Epoch 3/5\n",
      "3524/3524 [==============================] - 26s 8ms/step - loss: 0.3498 - accuracy: 0.8470 - f1_metric: 0.8483 - val_loss: 0.4396 - val_accuracy: 0.8240 - val_f1_metric: 0.8269\n",
      "Epoch 4/5\n",
      "3524/3524 [==============================] - 27s 8ms/step - loss: 0.3312 - accuracy: 0.8547 - f1_metric: 0.8559 - val_loss: 0.4705 - val_accuracy: 0.8112 - val_f1_metric: 0.8149\n",
      "Epoch 5/5\n",
      "3524/3524 [==============================] - 27s 8ms/step - loss: 0.3090 - accuracy: 0.8641 - f1_metric: 0.8651 - val_loss: 0.5291 - val_accuracy: 0.8087 - val_f1_metric: 0.8125\n",
      "Predicting for glam:\n",
      "Train on 3524 samples, validate on 392 samples\n",
      "Epoch 1/5\n",
      "3524/3524 [==============================] - 27s 8ms/step - loss: 0.3280 - accuracy: 0.8842 - f1_metric: 0.8851 - val_loss: 0.2424 - val_accuracy: 0.9209 - val_f1_metric: 0.9183\n",
      "Epoch 2/5\n",
      "3524/3524 [==============================] - 27s 8ms/step - loss: 0.2651 - accuracy: 0.8950 - f1_metric: 0.8939 - val_loss: 0.2269 - val_accuracy: 0.9235 - val_f1_metric: 0.9207\n",
      "Epoch 3/5\n",
      "3524/3524 [==============================] - 26s 7ms/step - loss: 0.2475 - accuracy: 0.9018 - f1_metric: 0.9006 - val_loss: 0.2184 - val_accuracy: 0.9133 - val_f1_metric: 0.9111\n",
      "Epoch 4/5\n",
      "3524/3524 [==============================] - 26s 7ms/step - loss: 0.2230 - accuracy: 0.9061 - f1_metric: 0.9048 - val_loss: 0.2214 - val_accuracy: 0.9209 - val_f1_metric: 0.9183\n",
      "Epoch 5/5\n",
      "3524/3524 [==============================] - 27s 8ms/step - loss: 0.2018 - accuracy: 0.9208 - f1_metric: 0.9215 - val_loss: 0.2293 - val_accuracy: 0.9107 - val_f1_metric: 0.9087\n",
      "Predicting for modern:\n",
      "Train on 3524 samples, validate on 392 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3524/3524 [==============================] - 27s 8ms/step - loss: 0.5697 - accuracy: 0.6918 - f1_metric: 0.6943 - val_loss: 0.6127 - val_accuracy: 0.6811 - val_f1_metric: 0.6707\n",
      "Epoch 2/5\n",
      "3524/3524 [==============================] - 26s 7ms/step - loss: 0.4923 - accuracy: 0.7605 - f1_metric: 0.7604 - val_loss: 0.6379 - val_accuracy: 0.6760 - val_f1_metric: 0.6659\n",
      "Epoch 3/5\n",
      "3524/3524 [==============================] - 27s 8ms/step - loss: 0.4637 - accuracy: 0.7806 - f1_metric: 0.7784 - val_loss: 0.6501 - val_accuracy: 0.6582 - val_f1_metric: 0.6490\n",
      "Epoch 4/5\n",
      "3524/3524 [==============================] - 27s 8ms/step - loss: 0.4412 - accuracy: 0.7980 - f1_metric: 0.7976 - val_loss: 0.7943 - val_accuracy: 0.6327 - val_f1_metric: 0.6034\n",
      "Epoch 5/5\n",
      "3524/3524 [==============================] - 27s 8ms/step - loss: 0.4073 - accuracy: 0.8119 - f1_metric: 0.8133 - val_loss: 0.7160 - val_accuracy: 0.6709 - val_f1_metric: 0.6611\n",
      "Predicting for retro:\n",
      "Train on 3524 samples, validate on 392 samples\n",
      "Epoch 1/5\n",
      "3524/3524 [==============================] - 27s 8ms/step - loss: 0.2307 - accuracy: 0.9342 - f1_metric: 0.9347 - val_loss: 0.1621 - val_accuracy: 0.9617 - val_f1_metric: 0.9639\n",
      "Epoch 2/5\n",
      "3524/3524 [==============================] - 26s 7ms/step - loss: 0.1924 - accuracy: 0.9421 - f1_metric: 0.9426 - val_loss: 0.1646 - val_accuracy: 0.9617 - val_f1_metric: 0.9639\n",
      "Epoch 3/5\n",
      "3524/3524 [==============================] - 27s 8ms/step - loss: 0.1766 - accuracy: 0.9435 - f1_metric: 0.9440 - val_loss: 0.1702 - val_accuracy: 0.9617 - val_f1_metric: 0.9639\n",
      "Epoch 4/5\n",
      "3524/3524 [==============================] - 26s 7ms/step - loss: 0.1570 - accuracy: 0.9475 - f1_metric: 0.9479 - val_loss: 0.1647 - val_accuracy: 0.9617 - val_f1_metric: 0.9639\n",
      "Epoch 5/5\n",
      "3524/3524 [==============================] - 26s 7ms/step - loss: 0.1434 - accuracy: 0.9509 - f1_metric: 0.9513 - val_loss: 0.1831 - val_accuracy: 0.9464 - val_f1_metric: 0.9495\n",
      "Predicting for romantic:\n",
      "Train on 3524 samples, validate on 392 samples\n",
      "Epoch 1/5\n",
      "3524/3524 [==============================] - 27s 8ms/step - loss: 0.3848 - accuracy: 0.8436 - f1_metric: 0.8429 - val_loss: 0.1925 - val_accuracy: 0.9541 - val_f1_metric: 0.9567\n",
      "Epoch 2/5\n",
      "3524/3524 [==============================] - 26s 7ms/step - loss: 0.3174 - accuracy: 0.8689 - f1_metric: 0.8699 - val_loss: 0.2339 - val_accuracy: 0.9337 - val_f1_metric: 0.9375\n",
      "Epoch 3/5\n",
      "3524/3524 [==============================] - 26s 7ms/step - loss: 0.2963 - accuracy: 0.8760 - f1_metric: 0.8770 - val_loss: 0.1805 - val_accuracy: 0.9490 - val_f1_metric: 0.9519\n",
      "Epoch 4/5\n",
      "3524/3524 [==============================] - 26s 7ms/step - loss: 0.2730 - accuracy: 0.8868 - f1_metric: 0.8857 - val_loss: 0.2315 - val_accuracy: 0.9260 - val_f1_metric: 0.9303\n",
      "Epoch 5/5\n",
      "3524/3524 [==============================] - 26s 7ms/step - loss: 0.2578 - accuracy: 0.8907 - f1_metric: 0.8916 - val_loss: 0.2369 - val_accuracy: 0.9286 - val_f1_metric: 0.9327\n"
     ]
    }
   ],
   "source": [
    "lstm_style_models = {}\n",
    "for style in sorted(styles):\n",
    "    print(f'Predicting for {style}:')\n",
    "    lstm_style_models[style] = value_model(style, styles_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coldweather prediction performance:\n",
      "Train on 3522 samples, validate on 392 samples\n",
      "Epoch 1/5\n",
      "3522/3522 [==============================] - 27s 8ms/step - loss: 0.2161 - accuracy: 0.9250 - f1_metric: 0.9257 - val_loss: 0.0926 - val_accuracy: 0.9694 - val_f1_metric: 0.9712\n",
      "Epoch 2/5\n",
      "3522/3522 [==============================] - 26s 7ms/step - loss: 0.1454 - accuracy: 0.9455 - f1_metric: 0.9459 - val_loss: 0.0906 - val_accuracy: 0.9745 - val_f1_metric: 0.9760\n",
      "Epoch 3/5\n",
      "3522/3522 [==============================] - 26s 8ms/step - loss: 0.1265 - accuracy: 0.9503 - f1_metric: 0.9507 - val_loss: 0.1433 - val_accuracy: 0.9388 - val_f1_metric: 0.9423\n",
      "Epoch 4/5\n",
      "3522/3522 [==============================] - 26s 7ms/step - loss: 0.1124 - accuracy: 0.9549 - f1_metric: 0.9510 - val_loss: 0.1674 - val_accuracy: 0.9311 - val_f1_metric: 0.9351\n",
      "Epoch 5/5\n",
      "3522/3522 [==============================] - 26s 7ms/step - loss: 0.1079 - accuracy: 0.9549 - f1_metric: 0.9552 - val_loss: 0.0805 - val_accuracy: 0.9719 - val_f1_metric: 0.9736\n",
      "daytonight prediction performance:\n",
      "Train on 3522 samples, validate on 392 samples\n",
      "Epoch 1/5\n",
      "3522/3522 [==============================] - 27s 8ms/step - loss: 0.5352 - accuracy: 0.7564 - f1_metric: 0.7584 - val_loss: 0.5857 - val_accuracy: 0.7423 - val_f1_metric: 0.7356\n",
      "Epoch 2/5\n",
      "3522/3522 [==============================] - 26s 7ms/step - loss: 0.4810 - accuracy: 0.7797 - f1_metric: 0.7815 - val_loss: 0.5754 - val_accuracy: 0.7372 - val_f1_metric: 0.7308\n",
      "Epoch 3/5\n",
      "3522/3522 [==============================] - 26s 7ms/step - loss: 0.4473 - accuracy: 0.7976 - f1_metric: 0.7950 - val_loss: 0.5445 - val_accuracy: 0.7423 - val_f1_metric: 0.7356\n",
      "Epoch 4/5\n",
      "3522/3522 [==============================] - 26s 7ms/step - loss: 0.4193 - accuracy: 0.8135 - f1_metric: 0.8108 - val_loss: 0.5579 - val_accuracy: 0.7449 - val_f1_metric: 0.7380\n",
      "Epoch 5/5\n",
      "3522/3522 [==============================] - 26s 7ms/step - loss: 0.3892 - accuracy: 0.8365 - f1_metric: 0.8378 - val_loss: 0.5954 - val_accuracy: 0.6760 - val_f1_metric: 0.6731\n",
      "nightout prediction performance:\n",
      "Train on 3522 samples, validate on 392 samples\n",
      "Epoch 1/5\n",
      "3522/3522 [==============================] - 27s 8ms/step - loss: 0.4975 - accuracy: 0.7649 - f1_metric: 0.7669 - val_loss: 0.4105 - val_accuracy: 0.8495 - val_f1_metric: 0.8510\n",
      "Epoch 2/5\n",
      "3522/3522 [==============================] - 26s 7ms/step - loss: 0.4343 - accuracy: 0.7976 - f1_metric: 0.7993 - val_loss: 0.4344 - val_accuracy: 0.7883 - val_f1_metric: 0.7933\n",
      "Epoch 3/5\n",
      "3522/3522 [==============================] - 26s 7ms/step - loss: 0.3905 - accuracy: 0.8126 - f1_metric: 0.8142 - val_loss: 0.4267 - val_accuracy: 0.7883 - val_f1_metric: 0.7933\n",
      "Epoch 4/5\n",
      "3522/3522 [==============================] - 26s 7ms/step - loss: 0.3644 - accuracy: 0.8302 - f1_metric: 0.8316 - val_loss: 0.4790 - val_accuracy: 0.7679 - val_f1_metric: 0.7740\n",
      "Epoch 5/5\n",
      "3522/3522 [==============================] - 27s 8ms/step - loss: 0.3350 - accuracy: 0.8450 - f1_metric: 0.8463 - val_loss: 0.4661 - val_accuracy: 0.7730 - val_f1_metric: 0.7788\n",
      "vacation prediction performance:\n",
      "Train on 3522 samples, validate on 392 samples\n",
      "Epoch 1/5\n",
      "3522/3522 [==============================] - 27s 8ms/step - loss: 0.4158 - accuracy: 0.8359 - f1_metric: 0.8373 - val_loss: 0.5138 - val_accuracy: 0.7781 - val_f1_metric: 0.7620\n",
      "Epoch 2/5\n",
      "3522/3522 [==============================] - 27s 8ms/step - loss: 0.3475 - accuracy: 0.8546 - f1_metric: 0.8559 - val_loss: 0.4210 - val_accuracy: 0.8087 - val_f1_metric: 0.7981\n",
      "Epoch 3/5\n",
      "3522/3522 [==============================] - 26s 7ms/step - loss: 0.3062 - accuracy: 0.8705 - f1_metric: 0.8716 - val_loss: 0.4419 - val_accuracy: 0.8189 - val_f1_metric: 0.8077\n",
      "Epoch 4/5\n",
      "3522/3522 [==============================] - 26s 7ms/step - loss: 0.2831 - accuracy: 0.8810 - f1_metric: 0.8820 - val_loss: 0.4283 - val_accuracy: 0.8240 - val_f1_metric: 0.8125\n",
      "Epoch 5/5\n",
      "3522/3522 [==============================] - 26s 7ms/step - loss: 0.2474 - accuracy: 0.8995 - f1_metric: 0.9003 - val_loss: 0.4469 - val_accuracy: 0.8010 - val_f1_metric: 0.7909\n",
      "weekend prediction performance:\n",
      "Train on 3522 samples, validate on 392 samples\n",
      "Epoch 1/5\n",
      "3522/3522 [==============================] - 27s 8ms/step - loss: 0.5189 - accuracy: 0.7689 - f1_metric: 0.7708 - val_loss: 0.5339 - val_accuracy: 0.7526 - val_f1_metric: 0.7452\n",
      "Epoch 2/5\n",
      "3522/3522 [==============================] - 26s 7ms/step - loss: 0.4541 - accuracy: 0.7967 - f1_metric: 0.7984 - val_loss: 0.5208 - val_accuracy: 0.7628 - val_f1_metric: 0.7548\n",
      "Epoch 3/5\n",
      "3522/3522 [==============================] - 26s 7ms/step - loss: 0.4101 - accuracy: 0.8146 - f1_metric: 0.8119 - val_loss: 0.5119 - val_accuracy: 0.7704 - val_f1_metric: 0.7620\n",
      "Epoch 4/5\n",
      "3522/3522 [==============================] - 26s 7ms/step - loss: 0.3746 - accuracy: 0.8268 - f1_metric: 0.8283 - val_loss: 0.5347 - val_accuracy: 0.7474 - val_f1_metric: 0.7332\n",
      "Epoch 5/5\n",
      "3522/3522 [==============================] - 26s 7ms/step - loss: 0.3481 - accuracy: 0.8450 - f1_metric: 0.8463 - val_loss: 0.5546 - val_accuracy: 0.7500 - val_f1_metric: 0.7356\n",
      "work prediction performance:\n",
      "Train on 3522 samples, validate on 392 samples\n",
      "Epoch 1/5\n",
      "3522/3522 [==============================] - 27s 8ms/step - loss: 0.5312 - accuracy: 0.7320 - f1_metric: 0.7342 - val_loss: 0.4428 - val_accuracy: 0.8138 - val_f1_metric: 0.8245\n",
      "Epoch 2/5\n",
      "3522/3522 [==============================] - 27s 8ms/step - loss: 0.4453 - accuracy: 0.7890 - f1_metric: 0.7866 - val_loss: 0.4120 - val_accuracy: 0.8163 - val_f1_metric: 0.8269\n",
      "Epoch 3/5\n",
      "3522/3522 [==============================] - 26s 8ms/step - loss: 0.4136 - accuracy: 0.8092 - f1_metric: 0.8066 - val_loss: 0.4380 - val_accuracy: 0.8061 - val_f1_metric: 0.8173\n",
      "Epoch 4/5\n",
      "3522/3522 [==============================] - 26s 7ms/step - loss: 0.3743 - accuracy: 0.8302 - f1_metric: 0.8232 - val_loss: 0.4072 - val_accuracy: 0.8189 - val_f1_metric: 0.8293\n",
      "Epoch 5/5\n",
      "3522/3522 [==============================] - 26s 7ms/step - loss: 0.3588 - accuracy: 0.8393 - f1_metric: 0.8407 - val_loss: 0.3893 - val_accuracy: 0.8418 - val_f1_metric: 0.8510\n",
      "workout prediction performance:\n",
      "Train on 3522 samples, validate on 392 samples\n",
      "Epoch 1/5\n",
      "3522/3522 [==============================] - 27s 8ms/step - loss: 0.1270 - accuracy: 0.9620 - f1_metric: 0.9623 - val_loss: 0.0312 - val_accuracy: 0.9872 - val_f1_metric: 0.9880\n",
      "Epoch 2/5\n",
      "3522/3522 [==============================] - 26s 7ms/step - loss: 0.0663 - accuracy: 0.9781 - f1_metric: 0.9783 - val_loss: 0.0342 - val_accuracy: 0.9872 - val_f1_metric: 0.9880\n",
      "Epoch 3/5\n",
      "3522/3522 [==============================] - 26s 7ms/step - loss: 0.0540 - accuracy: 0.9804 - f1_metric: 0.9806 - val_loss: 0.0358 - val_accuracy: 0.9847 - val_f1_metric: 0.9856\n",
      "Epoch 4/5\n",
      "3522/3522 [==============================] - 26s 7ms/step - loss: 0.0445 - accuracy: 0.9844 - f1_metric: 0.9845 - val_loss: 0.0388 - val_accuracy: 0.9847 - val_f1_metric: 0.9856\n",
      "Epoch 5/5\n",
      "3522/3522 [==============================] - 27s 8ms/step - loss: 0.0335 - accuracy: 0.9858 - f1_metric: 0.9859 - val_loss: 0.0463 - val_accuracy: 0.9847 - val_f1_metric: 0.9856\n"
     ]
    }
   ],
   "source": [
    "lstm_occasion_models = {}\n",
    "for occasion in sorted(occasions):\n",
    "    print(f'{occasion} prediction performance:')\n",
    "    lstm_occasion_models[occasion] = value_model(occasion, occasion_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting output using traditional ML methods\n",
    "def ml_predict_output(dataframe, tag, vector):\n",
    "    df = dataframe.copy()\n",
    "    for col in df.columns:\n",
    "        df = dataframe.copy()\n",
    "        if col in category:\n",
    "            slicingid = col\n",
    "            break\n",
    "    X = pd.concat([df.loc[:,slicingid:],pd.DataFrame(vector).reindex(df.loc[:,slicingid:].index)], axis=1).fillna(0)\n",
    "    if tag == 'casual':\n",
    "        return best_style_models[tag+'_target'].predict(X.values)\n",
    "    return best_occassion_models[tag+'_target'].predict(X.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting output using DL methods\n",
    "def predict_output(input_df, tag, occ=False):\n",
    "    tf.random.set_seed(RANDOM_SEED)\n",
    "    input_df = input_df.fillna('')\n",
    "    input_df['input'] = input_df[['brand','brand_category','product_full_name','description','details']]\\\n",
    "                        .agg(' '.join, axis=1).str.lower()\n",
    "    input_df['input'] = input_df['input'].replace(r\"[^a-z0-9\\s]+\", \"\")\n",
    "    inputdata=input_df['input'].tolist()\n",
    "    stopwords_removed_docs = list(\n",
    "        map(lambda doc: \" \".join([token.text for token in nlp(doc) if not token.is_stop]), inputdata))\n",
    "    tokenizer.fit_on_texts(stopwords_removed_docs)\n",
    "    encoded_docs = integer_encode_documents(stopwords_removed_docs, tokenizer)\n",
    "    padded_docs = pad_sequences(encoded_docs, padding='post')\n",
    "    if occ:\n",
    "        predictions = [pred[1]>0.5 for pred in lstm_occasion_models[tag].predict(padded_docs)]\n",
    "    else:\n",
    "        predictions = [pred[1]>0.5 for pred in lstm_style_models[tag].predict(padded_docs)]\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_df(input_df, input_occasion_df, input_style_df):\n",
    "    styles_pred = {}\n",
    "    occasions_pred = {}\n",
    "    for style in styles:\n",
    "        #can add more better performing categories to below list\n",
    "        #if ML models perform better\n",
    "        if style in ['casual','modern']: #use tradtional ML for better performance\n",
    "            styles_pred[style] = ml_predict_output(input_style_df, style, input_style_combined_vectors)\n",
    "        else:\n",
    "            styles_pred[style] = predict_output(input_df, style)\n",
    "    for occasion in occasions:\n",
    "        if occasion in ['daytonight', 'weekend']: #use tradtional ML for better performance\n",
    "            occasions_pred[occasion] = ml_predict_output(input_occasion_df, occasion, input_occasion_combined_vectors)\n",
    "        else:\n",
    "            occasions_pred[occasion] = predict_output(input_df, occasion, occ=True)\n",
    "    return styles_pred, occasions_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>product_full_name</th>\n",
       "      <th>description</th>\n",
       "      <th>brand_category</th>\n",
       "      <th>details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bottega veneta</td>\n",
       "      <td>Large leather-trimmed linen tote</td>\n",
       "      <td>beige linen, black leather (calf) open top com...</td>\n",
       "      <td>bags,shoulderbags</td>\n",
       "      <td>This item's measurements are:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>marc jacobs</td>\n",
       "      <td>The Jewelled Button Sweater</td>\n",
       "      <td>jewel-embellished shoulder buttons add eleganc...</td>\n",
       "      <td>women,sweaters,cashmere</td>\n",
       "      <td>Roundneck\\nShort sleeves\\nShoulder buttons\\nWo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>frame</td>\n",
       "      <td>Les Second - Medium--NOIR</td>\n",
       "      <td>minimal, modern styling meets refined luxury i...</td>\n",
       "      <td>accessories</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>sarto by franco sarto</td>\n",
       "      <td>Visa Mule</td>\n",
       "      <td>an asymmetrical topline puts a modern spin on ...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>True to size.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951</th>\n",
       "      <td>banana republic</td>\n",
       "      <td>Madison 12-Hour Loafer Pump</td>\n",
       "      <td>everything you love about our original madison...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Everything you love about our original Madison...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158987</th>\n",
       "      <td>orseund iris</td>\n",
       "      <td>Night Out open-back ruched satin blouse</td>\n",
       "      <td>cream satin tie and concealed snap fastenings ...</td>\n",
       "      <td>clothing,tops,blouses</td>\n",
       "      <td>Fits true to size, take your normal size \\nDes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158989</th>\n",
       "      <td>reformation</td>\n",
       "      <td>Jane Sweater</td>\n",
       "      <td>soft spot.this is a slightly cropped sweater w...</td>\n",
       "      <td>full fashion</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158993</th>\n",
       "      <td>veronica beard</td>\n",
       "      <td>Crosbie High-Rise Wide-Leg</td>\n",
       "      <td>our elongating crosbie jeans feature a flatter...</td>\n",
       "      <td>jeans</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158995</th>\n",
       "      <td>reformation</td>\n",
       "      <td>Jessie High Crop Boot</td>\n",
       "      <td>denim - your uniform since forever.this is a h...</td>\n",
       "      <td>jeans</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158999</th>\n",
       "      <td>bailey 44</td>\n",
       "      <td>Travis Pant</td>\n",
       "      <td>the straight, cropped silhouette of the travis...</td>\n",
       "      <td>pants</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3904 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        brand                        product_full_name  \\\n",
       "0              bottega veneta         Large leather-trimmed linen tote   \n",
       "68                marc jacobs              The Jewelled Button Sweater   \n",
       "150                     frame                Les Second - Medium--NOIR   \n",
       "836     sarto by franco sarto                                Visa Mule   \n",
       "951           banana republic              Madison 12-Hour Loafer Pump   \n",
       "...                       ...                                      ...   \n",
       "158987           orseund iris  Night Out open-back ruched satin blouse   \n",
       "158989            reformation                             Jane Sweater   \n",
       "158993         veronica beard               Crosbie High-Rise Wide-Leg   \n",
       "158995            reformation                    Jessie High Crop Boot   \n",
       "158999              bailey 44                              Travis Pant   \n",
       "\n",
       "                                              description  \\\n",
       "0       beige linen, black leather (calf) open top com...   \n",
       "68      jewel-embellished shoulder buttons add eleganc...   \n",
       "150     minimal, modern styling meets refined luxury i...   \n",
       "836     an asymmetrical topline puts a modern spin on ...   \n",
       "951     everything you love about our original madison...   \n",
       "...                                                   ...   \n",
       "158987  cream satin tie and concealed snap fastenings ...   \n",
       "158989  soft spot.this is a slightly cropped sweater w...   \n",
       "158993  our elongating crosbie jeans feature a flatter...   \n",
       "158995  denim - your uniform since forever.this is a h...   \n",
       "158999  the straight, cropped silhouette of the travis...   \n",
       "\n",
       "                 brand_category  \\\n",
       "0             bags,shoulderbags   \n",
       "68      women,sweaters,cashmere   \n",
       "150                 accessories   \n",
       "836                     unknown   \n",
       "951                     unknown   \n",
       "...                         ...   \n",
       "158987    clothing,tops,blouses   \n",
       "158989             full fashion   \n",
       "158993                    jeans   \n",
       "158995                    jeans   \n",
       "158999                    pants   \n",
       "\n",
       "                                                  details  \n",
       "0                           This item's measurements are:  \n",
       "68      Roundneck\\nShort sleeves\\nShoulder buttons\\nWo...  \n",
       "150                                                   NaN  \n",
       "836                                         True to size.  \n",
       "951     Everything you love about our original Madison...  \n",
       "...                                                   ...  \n",
       "158987  Fits true to size, take your normal size \\nDes...  \n",
       "158989                                                NaN  \n",
       "158993                                                NaN  \n",
       "158995                                                NaN  \n",
       "158999                                                NaN  \n",
       "\n",
       "[3904 rows x 5 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "styles_pred, occasions_pred = output_df(input_df.fillna(''), input_occasion_df, input_style_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "styles_out = []\n",
    "occasions_out = []\n",
    "for i in range(len(input_df)):\n",
    "    style_o = []\n",
    "    occasion_o = []\n",
    "    for style in styles_pred.keys():\n",
    "        if styles_pred[style][i]:\n",
    "            style_o.append(style)\n",
    "    styles_out.append('/'.join(style_o))\n",
    "    for occasion in occasions_pred.keys():\n",
    "        if occasions_pred[occasion][i]:\n",
    "            occasion_o.append(occasion)\n",
    "    occasions_out.append('/'.join(occasion_o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df['style'] = styles_out\n",
    "input_df['occasion'] = occasions_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our methodology involves preliminary data cleaning (regex, remove stopwords, lemmatization), creating one hot for category and label encoding brands.\n",
    "\n",
    "We implemented both deep learning & traditional NLP methods with classical ML methods (TF-IDF and word embeddings).\n",
    "\n",
    "Given the tight time frame, for deep learning, we only concatenated text and used pre-trained embedding.\n",
    "\n",
    "This way of training also assumed the concatenated input strings are of a single sequence.\n",
    "\n",
    "Given more time, we can seperate the input strings (description,details,fullname) sequences with categorical variables in our deep learning model architecture.\n",
    "\n",
    "We used F1-scores as our final evaluation metrics to assess our models because we want to achieve a good balance between precision & recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
